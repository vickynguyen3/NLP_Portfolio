{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "WordNet is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dress.n.01'),\n",
       " Synset('attire.n.01'),\n",
       " Synset('apparel.n.01'),\n",
       " Synset('dress.v.01'),\n",
       " Synset('dress.v.02'),\n",
       " Synset('dress.v.03'),\n",
       " Synset('dress.v.04'),\n",
       " Synset('preen.v.03'),\n",
       " Synset('dress.v.06'),\n",
       " Synset('dress.v.07'),\n",
       " Synset('trim.v.06'),\n",
       " Synset('dress.v.09'),\n",
       " Synset('dress.v.10'),\n",
       " Synset('snip.v.02'),\n",
       " Synset('dress.v.12'),\n",
       " Synset('dress.v.13'),\n",
       " Synset('dress.v.14'),\n",
       " Synset('dress.v.15'),\n",
       " Synset('dress.v.16'),\n",
       " Synset('full-dress.s.01'),\n",
       " Synset('dress.s.02')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output all synsets (synonym sets) from noun\n",
    "wn.synsets('dress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Definitions ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'clothing in general'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract definition \n",
    "print('---- Definitions ----')\n",
    "wn.synset('apparel.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Examples ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['she was refined in her choice of apparel',\n",
       " 'he always bought his clothes at the same store',\n",
       " 'fastidious about his dress']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract usage examples\n",
    "wn.synset('apparel.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Lemmas ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Lemma('apparel.n.01.apparel'),\n",
       " Lemma('apparel.n.01.wearing_apparel'),\n",
       " Lemma('apparel.n.01.dress'),\n",
       " Lemma('apparel.n.01.clothes')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract lemmas\n",
    "wn.synset('apparel.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('clothing.n.01')\n",
      "Synset('consumer_goods.n.01')\n",
      "Synset('commodity.n.01')\n",
      "Synset('artifact.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('object.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "# Traverse up the WordNet hierarchy\n",
    "\n",
    "hy = wn.synset('apparel.n.01').hypernyms()[0]\n",
    "# hierarchy for nouns has 'entity' at the top\n",
    "top = wn.synset('entity.n.01')\n",
    "\n",
    "while hy:\n",
    "    print(hy)\n",
    "    if hy == top:\n",
    "        break\n",
    "    if hy.hypernyms():\n",
    "        hy = hy.hypernyms()[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my observation, I see that WordNet organizes the nouns to be outputted first, then the verbs, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:  [Synset('clothing.n.01')]\n",
      "Hyponyms:  [Synset('workwear.n.01')]\n",
      "Meronyms:  [] []\n",
      "Holoynyms:  []\n",
      "Antonyms:  []\n"
     ]
    }
   ],
   "source": [
    "# output hypernymns, hyponyms, meronyms, holonyms, antonyms (or an empty list if none exist)\n",
    "\n",
    "# Hypernyms\n",
    "print('Hypernyms: ', wn.synset('apparel.n.01').hypernyms())\n",
    "\n",
    "# Hyponyms\n",
    "print('Hyponyms: ',  wn.synset('apparel.n.01').hyponyms())\n",
    "\n",
    "# Meronyms\n",
    "print('Meronyms: ', wn.synset('apparel.n.01').part_meronyms(), wn.synset('apparel.n.01').substance_meronyms())\n",
    "\n",
    "# Holonyms\n",
    "print('Holoynyms: ', wn.synset('apparel.n.01').member_holonyms())\n",
    "\n",
    "# Antonyms\n",
    "print('Antonyms: ', wn.synset('apparel.n.01').lemmas()[0].antonyms())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('sing.v.01'),\n",
       " Synset('sing.v.02'),\n",
       " Synset('sing.v.03'),\n",
       " Synset('whistle.v.05'),\n",
       " Synset('spill_the_beans.v.01')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output all synsets from verb\n",
    "wn.synsets('sing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produce tones with the voice'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract definition \n",
    "wn.synset('sing.v.02').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She was singing while she was cooking', 'My brother sings very well']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract usage examples\n",
    "wn.synset('sing.v.02').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('sing.v.02.sing')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract lemmas\n",
    "wn.synset('sing.v.02').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('talk.v.02'),\n",
       " Synset('communicate.v.02'),\n",
       " Synset('interact.v.01'),\n",
       " Synset('act.v.01')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traverse up the WordNet hierarchy\n",
    "sing = wn.synset('sing.v.02')\n",
    "hy = lambda s: s.hypernyms()\n",
    "list(sing.closure(hy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation of the Way WordNet is Organized for Verbs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "hug\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use morphy to find many different forms of the word\n",
    "print(wn.morphy('loving'))\n",
    "print(wn.morphy('hugged', wn.VERB))\n",
    "print(wn.morphy('hugged', wn.ADV))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wu-Palmer Similarity Metric and Lesk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wu-Palmer Similarity Metric\n",
    "wn.wup_similarity(wn.synset('lady.n.01'), wn.synset('female.n.01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation of Wu-Palmer and Lesk Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentiWordNet\n",
    "functionality\n",
    "possible use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<expectation.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score:  0.0\n",
      "Negative Score:  0.0\n",
      "Objective Score:  1.0 \n",
      "\n",
      "<anticipation.n.04: PosScore=0.5 NegScore=0.0>\n",
      "Positive Score:  0.5\n",
      "Negative Score:  0.0\n",
      "Objective Score:  0.5 \n",
      "\n",
      "<expectation.n.03: PosScore=0.0 NegScore=0.125>\n",
      "Positive Score:  0.0\n",
      "Negative Score:  0.125\n",
      "Objective Score:  0.875 \n",
      "\n",
      "<arithmetic_mean.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score:  0.0\n",
      "Negative Score:  0.0\n",
      "Objective Score:  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# an emotionally charged word\n",
    "expect = swn.senti_synsets('expectation')\n",
    "\n",
    "# find its senti-synsets and output the polarity scores for each word\n",
    "for ss in list(expect):\n",
    "    expect = ss\n",
    "    print(expect)\n",
    "    print('Positive Score: ', expect.pos_score())\n",
    "    print('Negative Score: ', expect.neg_score())\n",
    "    print('Objective Score: ', expect.obj_score(), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expecting', 'to', 'have', 'a', 'delivery', 'today']\n",
      "<expect.v.01: PosScore=0.25 NegScore=0.25>\n",
      "Positive Score:  0.25\n",
      "Negative Score:  0.25\n",
      "Objective Score:  0.5 \n",
      "\n",
      "<rich_person.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score:  0.0\n",
      "Negative Score:  0.0\n",
      "Objective Score:  1.0 \n",
      "\n",
      "<angstrom.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score:  0.0\n",
      "Negative Score:  0.0\n",
      "Objective Score:  1.0 \n",
      "\n",
      "<delivery.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score:  0.0\n",
      "Negative Score:  0.0\n",
      "Objective Score:  1.0 \n",
      "\n",
      "<today.n.01: PosScore=0.125 NegScore=0.0>\n",
      "Positive Score:  0.125\n",
      "Negative Score:  0.0\n",
      "Objective Score:  0.875 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "sentence = 'expecting to have a delivery today'\n",
    "neg = 0\n",
    "pos = 0\n",
    "words = sentence.split()\n",
    "\n",
    "print(words)\n",
    "# output polarity for each word in the sentence\n",
    "for w in words:\n",
    "    ss_list = list(swn.senti_synsets(w))\n",
    "\n",
    "    if ss_list:\n",
    "        syn = ss_list[0] \n",
    "        print(syn)\n",
    "        print('Positive Score: ', syn.pos_score())\n",
    "        print('Negative Score: ', syn.neg_score())\n",
    "        print('Objective Score: ', syn.obj_score(), '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation of the Scores and Utility of Knowing these Scores in an NLP application"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocation\n",
    "Collocation is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# output collocations for text4, Inaugural Corpus\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m text4\u001b[39m.\u001b[39mcollocations()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text4' is not defined"
     ]
    }
   ],
   "source": [
    "# output collocations for text4, Inaugural Corpus\n",
    "from nltk.corpus import *\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one of the collocations identified by NLTK\n",
    "\n",
    "# calculate mutual information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentary on the Results of the Mutual Information Formula and my Interpretation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8c3ccee6358082b56d4bf6497bbfb0bbb5ad3534c94c8a9fbdfa83e71dff5fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
